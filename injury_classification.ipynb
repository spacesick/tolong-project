{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3"
      ],
      "metadata": {
        "id": "1Bo7GXnIcbJh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Google drive"
      ],
      "metadata": {
        "id": "0UKrVzOkdB54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tDC_sKDFQjD",
        "outputId": "ced91597-2b3e-4d61-9f9b-c226c9c28b77"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import dataset and model checkpoint"
      ],
      "metadata": {
        "id": "LgJCgrqTdIWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = \"/content/drive/MyDrive/injurydataset\"\n",
        "trn_path = os.path.join(DATASET_PATH, \"train\")\n",
        "val_path = os.path.join(DATASET_PATH, \"validation\")\n",
        "\n",
        "CKPT_PATH = \"/content/drive/MyDrive/mymodelckpt/70.ckpt\""
      ],
      "metadata": {
        "id": "VPuWEjTIbm66"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trn_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "  rescale=1./255.,\n",
        "  rotation_range=90,\n",
        "  width_shift_range=0.2,\n",
        "  height_shift_range=0.2,\n",
        "  shear_range=0.2,\n",
        "  zoom_range=0.2,\n",
        "  horizontal_flip=True,\n",
        "  fill_mode='wrap'\n",
        ")\n",
        "\n",
        "trn_generator = trn_datagen.flow_from_directory(\n",
        "  directory=trn_path,\n",
        "  target_size=(224, 224),\n",
        "  batch_size=32,\n",
        ") \n",
        "\n",
        "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "  rescale=1./255.\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "  directory=val_path,\n",
        "  target_size=(224, 224),\n",
        "  batch_size=32,\n",
        ") "
      ],
      "metadata": {
        "id": "BXtzo2RRcYID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cefbf4e-cedd-4930-f234-a1a34a0fd0dc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 342 images belonging to 7 classes.\n",
            "Found 89 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = []\n",
        "loss = []\n",
        "val_acc = []\n",
        "val_loss = []"
      ],
      "metadata": {
        "id": "uTbVmE9XtFKj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "InceptionV3(\n",
        "  weights=\"imagenet\",\n",
        "  include_top=False,\n",
        "  input_shape=(224, 224, 3)\n",
        ").summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1vmpiQaacEy",
        "outputId": "e40f03bc-8bc1-4e46-8f7d-cdc3ff6d7adb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_31 (InputLayer)          [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)             (None, 111, 111, 32  864         ['input_31[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_94 (BatchN  (None, 111, 111, 32  96         ['conv2d_94[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_94 (Activation)     (None, 111, 111, 32  0           ['batch_normalization_94[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)             (None, 109, 109, 32  9216        ['activation_94[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_95 (BatchN  (None, 109, 109, 32  96         ['conv2d_95[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_95 (Activation)     (None, 109, 109, 32  0           ['batch_normalization_95[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)             (None, 109, 109, 64  18432       ['activation_95[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_96 (BatchN  (None, 109, 109, 64  192        ['conv2d_96[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_96 (Activation)     (None, 109, 109, 64  0           ['batch_normalization_96[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, 54, 54, 64)  0           ['activation_96[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_97 (Conv2D)             (None, 54, 54, 80)   5120        ['max_pooling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_97 (BatchN  (None, 54, 54, 80)  240         ['conv2d_97[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_97 (Activation)     (None, 54, 54, 80)   0           ['batch_normalization_97[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_98 (Conv2D)             (None, 52, 52, 192)  138240      ['activation_97[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_98 (BatchN  (None, 52, 52, 192)  576        ['conv2d_98[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_98 (Activation)     (None, 52, 52, 192)  0           ['batch_normalization_98[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPooling2D)  (None, 25, 25, 192)  0          ['activation_98[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_102 (Conv2D)            (None, 25, 25, 64)   12288       ['max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_102 (Batch  (None, 25, 25, 64)  192         ['conv2d_102[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_102 (Activation)    (None, 25, 25, 64)   0           ['batch_normalization_102[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_100 (Conv2D)            (None, 25, 25, 48)   9216        ['max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_103 (Conv2D)            (None, 25, 25, 96)   55296       ['activation_102[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_100 (Batch  (None, 25, 25, 48)  144         ['conv2d_100[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_103 (Batch  (None, 25, 25, 96)  288         ['conv2d_103[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_100 (Activation)    (None, 25, 25, 48)   0           ['batch_normalization_100[0][0]']\n",
            "                                                                                                  \n",
            " activation_103 (Activation)    (None, 25, 25, 96)   0           ['batch_normalization_103[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_9 (AveragePo  (None, 25, 25, 192)  0          ['max_pooling2d_5[0][0]']        \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_99 (Conv2D)             (None, 25, 25, 64)   12288       ['max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_101 (Conv2D)            (None, 25, 25, 64)   76800       ['activation_100[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_104 (Conv2D)            (None, 25, 25, 96)   82944       ['activation_103[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_105 (Conv2D)            (None, 25, 25, 32)   6144        ['average_pooling2d_9[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_99 (BatchN  (None, 25, 25, 64)  192         ['conv2d_99[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_101 (Batch  (None, 25, 25, 64)  192         ['conv2d_101[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_104 (Batch  (None, 25, 25, 96)  288         ['conv2d_104[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_105 (Batch  (None, 25, 25, 32)  96          ['conv2d_105[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_99 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_99[0][0]'] \n",
            "                                                                                                  \n",
            " activation_101 (Activation)    (None, 25, 25, 64)   0           ['batch_normalization_101[0][0]']\n",
            "                                                                                                  \n",
            " activation_104 (Activation)    (None, 25, 25, 96)   0           ['batch_normalization_104[0][0]']\n",
            "                                                                                                  \n",
            " activation_105 (Activation)    (None, 25, 25, 32)   0           ['batch_normalization_105[0][0]']\n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)           (None, 25, 25, 256)  0           ['activation_99[0][0]',          \n",
            "                                                                  'activation_101[0][0]',         \n",
            "                                                                  'activation_104[0][0]',         \n",
            "                                                                  'activation_105[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_109 (Conv2D)            (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_109 (Batch  (None, 25, 25, 64)  192         ['conv2d_109[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_109 (Activation)    (None, 25, 25, 64)   0           ['batch_normalization_109[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_107 (Conv2D)            (None, 25, 25, 48)   12288       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_110 (Conv2D)            (None, 25, 25, 96)   55296       ['activation_109[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_107 (Batch  (None, 25, 25, 48)  144         ['conv2d_107[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_110 (Batch  (None, 25, 25, 96)  288         ['conv2d_110[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_107 (Activation)    (None, 25, 25, 48)   0           ['batch_normalization_107[0][0]']\n",
            "                                                                                                  \n",
            " activation_110 (Activation)    (None, 25, 25, 96)   0           ['batch_normalization_110[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_10 (AverageP  (None, 25, 25, 256)  0          ['mixed0[0][0]']                 \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_106 (Conv2D)            (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_108 (Conv2D)            (None, 25, 25, 64)   76800       ['activation_107[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_111 (Conv2D)            (None, 25, 25, 96)   82944       ['activation_110[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_112 (Conv2D)            (None, 25, 25, 64)   16384       ['average_pooling2d_10[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_106 (Batch  (None, 25, 25, 64)  192         ['conv2d_106[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_108 (Batch  (None, 25, 25, 64)  192         ['conv2d_108[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_111 (Batch  (None, 25, 25, 96)  288         ['conv2d_111[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_112 (Batch  (None, 25, 25, 64)  192         ['conv2d_112[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_106 (Activation)    (None, 25, 25, 64)   0           ['batch_normalization_106[0][0]']\n",
            "                                                                                                  \n",
            " activation_108 (Activation)    (None, 25, 25, 64)   0           ['batch_normalization_108[0][0]']\n",
            "                                                                                                  \n",
            " activation_111 (Activation)    (None, 25, 25, 96)   0           ['batch_normalization_111[0][0]']\n",
            "                                                                                                  \n",
            " activation_112 (Activation)    (None, 25, 25, 64)   0           ['batch_normalization_112[0][0]']\n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)           (None, 25, 25, 288)  0           ['activation_106[0][0]',         \n",
            "                                                                  'activation_108[0][0]',         \n",
            "                                                                  'activation_111[0][0]',         \n",
            "                                                                  'activation_112[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_116 (Conv2D)            (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_116 (Batch  (None, 25, 25, 64)  192         ['conv2d_116[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_116 (Activation)    (None, 25, 25, 64)   0           ['batch_normalization_116[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_114 (Conv2D)            (None, 25, 25, 48)   13824       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_117 (Conv2D)            (None, 25, 25, 96)   55296       ['activation_116[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_114 (Batch  (None, 25, 25, 48)  144         ['conv2d_114[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_117 (Batch  (None, 25, 25, 96)  288         ['conv2d_117[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_114 (Activation)    (None, 25, 25, 48)   0           ['batch_normalization_114[0][0]']\n",
            "                                                                                                  \n",
            " activation_117 (Activation)    (None, 25, 25, 96)   0           ['batch_normalization_117[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_11 (AverageP  (None, 25, 25, 288)  0          ['mixed1[0][0]']                 \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_113 (Conv2D)            (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_115 (Conv2D)            (None, 25, 25, 64)   76800       ['activation_114[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_118 (Conv2D)            (None, 25, 25, 96)   82944       ['activation_117[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_119 (Conv2D)            (None, 25, 25, 64)   18432       ['average_pooling2d_11[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_113 (Batch  (None, 25, 25, 64)  192         ['conv2d_113[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_115 (Batch  (None, 25, 25, 64)  192         ['conv2d_115[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_118 (Batch  (None, 25, 25, 96)  288         ['conv2d_118[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_119 (Batch  (None, 25, 25, 64)  192         ['conv2d_119[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_113 (Activation)    (None, 25, 25, 64)   0           ['batch_normalization_113[0][0]']\n",
            "                                                                                                  \n",
            " activation_115 (Activation)    (None, 25, 25, 64)   0           ['batch_normalization_115[0][0]']\n",
            "                                                                                                  \n",
            " activation_118 (Activation)    (None, 25, 25, 96)   0           ['batch_normalization_118[0][0]']\n",
            "                                                                                                  \n",
            " activation_119 (Activation)    (None, 25, 25, 64)   0           ['batch_normalization_119[0][0]']\n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)           (None, 25, 25, 288)  0           ['activation_113[0][0]',         \n",
            "                                                                  'activation_115[0][0]',         \n",
            "                                                                  'activation_118[0][0]',         \n",
            "                                                                  'activation_119[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_121 (Conv2D)            (None, 25, 25, 64)   18432       ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_121 (Batch  (None, 25, 25, 64)  192         ['conv2d_121[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_121 (Activation)    (None, 25, 25, 64)   0           ['batch_normalization_121[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_122 (Conv2D)            (None, 25, 25, 96)   55296       ['activation_121[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_122 (Batch  (None, 25, 25, 96)  288         ['conv2d_122[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_122 (Activation)    (None, 25, 25, 96)   0           ['batch_normalization_122[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_120 (Conv2D)            (None, 12, 12, 384)  995328      ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_123 (Conv2D)            (None, 12, 12, 96)   82944       ['activation_122[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_120 (Batch  (None, 12, 12, 384)  1152       ['conv2d_120[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_123 (Batch  (None, 12, 12, 96)  288         ['conv2d_123[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_120 (Activation)    (None, 12, 12, 384)  0           ['batch_normalization_120[0][0]']\n",
            "                                                                                                  \n",
            " activation_123 (Activation)    (None, 12, 12, 96)   0           ['batch_normalization_123[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPooling2D)  (None, 12, 12, 288)  0          ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)           (None, 12, 12, 768)  0           ['activation_120[0][0]',         \n",
            "                                                                  'activation_123[0][0]',         \n",
            "                                                                  'max_pooling2d_6[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_128 (Conv2D)            (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_128 (Batch  (None, 12, 12, 128)  384        ['conv2d_128[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_128 (Activation)    (None, 12, 12, 128)  0           ['batch_normalization_128[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_129 (Conv2D)            (None, 12, 12, 128)  114688      ['activation_128[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_129 (Batch  (None, 12, 12, 128)  384        ['conv2d_129[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_129 (Activation)    (None, 12, 12, 128)  0           ['batch_normalization_129[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_125 (Conv2D)            (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_130 (Conv2D)            (None, 12, 12, 128)  114688      ['activation_129[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_125 (Batch  (None, 12, 12, 128)  384        ['conv2d_125[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_130 (Batch  (None, 12, 12, 128)  384        ['conv2d_130[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_125 (Activation)    (None, 12, 12, 128)  0           ['batch_normalization_125[0][0]']\n",
            "                                                                                                  \n",
            " activation_130 (Activation)    (None, 12, 12, 128)  0           ['batch_normalization_130[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_126 (Conv2D)            (None, 12, 12, 128)  114688      ['activation_125[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_131 (Conv2D)            (None, 12, 12, 128)  114688      ['activation_130[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_126 (Batch  (None, 12, 12, 128)  384        ['conv2d_126[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_131 (Batch  (None, 12, 12, 128)  384        ['conv2d_131[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_126 (Activation)    (None, 12, 12, 128)  0           ['batch_normalization_126[0][0]']\n",
            "                                                                                                  \n",
            " activation_131 (Activation)    (None, 12, 12, 128)  0           ['batch_normalization_131[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_12 (AverageP  (None, 12, 12, 768)  0          ['mixed3[0][0]']                 \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_124 (Conv2D)            (None, 12, 12, 192)  147456      ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_127 (Conv2D)            (None, 12, 12, 192)  172032      ['activation_126[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_132 (Conv2D)            (None, 12, 12, 192)  172032      ['activation_131[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_133 (Conv2D)            (None, 12, 12, 192)  147456      ['average_pooling2d_12[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_124 (Batch  (None, 12, 12, 192)  576        ['conv2d_124[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_127 (Batch  (None, 12, 12, 192)  576        ['conv2d_127[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_132 (Batch  (None, 12, 12, 192)  576        ['conv2d_132[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_133 (Batch  (None, 12, 12, 192)  576        ['conv2d_133[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_124 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_124[0][0]']\n",
            "                                                                                                  \n",
            " activation_127 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_127[0][0]']\n",
            "                                                                                                  \n",
            " activation_132 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_132[0][0]']\n",
            "                                                                                                  \n",
            " activation_133 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_133[0][0]']\n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)           (None, 12, 12, 768)  0           ['activation_124[0][0]',         \n",
            "                                                                  'activation_127[0][0]',         \n",
            "                                                                  'activation_132[0][0]',         \n",
            "                                                                  'activation_133[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_138 (Conv2D)            (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_138 (Batch  (None, 12, 12, 160)  480        ['conv2d_138[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_138 (Activation)    (None, 12, 12, 160)  0           ['batch_normalization_138[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_139 (Conv2D)            (None, 12, 12, 160)  179200      ['activation_138[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_139 (Batch  (None, 12, 12, 160)  480        ['conv2d_139[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_139 (Activation)    (None, 12, 12, 160)  0           ['batch_normalization_139[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_135 (Conv2D)            (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_140 (Conv2D)            (None, 12, 12, 160)  179200      ['activation_139[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_135 (Batch  (None, 12, 12, 160)  480        ['conv2d_135[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_140 (Batch  (None, 12, 12, 160)  480        ['conv2d_140[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_135 (Activation)    (None, 12, 12, 160)  0           ['batch_normalization_135[0][0]']\n",
            "                                                                                                  \n",
            " activation_140 (Activation)    (None, 12, 12, 160)  0           ['batch_normalization_140[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_136 (Conv2D)            (None, 12, 12, 160)  179200      ['activation_135[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_141 (Conv2D)            (None, 12, 12, 160)  179200      ['activation_140[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_136 (Batch  (None, 12, 12, 160)  480        ['conv2d_136[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_141 (Batch  (None, 12, 12, 160)  480        ['conv2d_141[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_136 (Activation)    (None, 12, 12, 160)  0           ['batch_normalization_136[0][0]']\n",
            "                                                                                                  \n",
            " activation_141 (Activation)    (None, 12, 12, 160)  0           ['batch_normalization_141[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_13 (AverageP  (None, 12, 12, 768)  0          ['mixed4[0][0]']                 \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_134 (Conv2D)            (None, 12, 12, 192)  147456      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_137 (Conv2D)            (None, 12, 12, 192)  215040      ['activation_136[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_142 (Conv2D)            (None, 12, 12, 192)  215040      ['activation_141[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_143 (Conv2D)            (None, 12, 12, 192)  147456      ['average_pooling2d_13[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_134 (Batch  (None, 12, 12, 192)  576        ['conv2d_134[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_137 (Batch  (None, 12, 12, 192)  576        ['conv2d_137[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_142 (Batch  (None, 12, 12, 192)  576        ['conv2d_142[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_143 (Batch  (None, 12, 12, 192)  576        ['conv2d_143[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_134 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_134[0][0]']\n",
            "                                                                                                  \n",
            " activation_137 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_137[0][0]']\n",
            "                                                                                                  \n",
            " activation_142 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_142[0][0]']\n",
            "                                                                                                  \n",
            " activation_143 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_143[0][0]']\n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)           (None, 12, 12, 768)  0           ['activation_134[0][0]',         \n",
            "                                                                  'activation_137[0][0]',         \n",
            "                                                                  'activation_142[0][0]',         \n",
            "                                                                  'activation_143[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_148 (Conv2D)            (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_148 (Batch  (None, 12, 12, 160)  480        ['conv2d_148[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_148 (Activation)    (None, 12, 12, 160)  0           ['batch_normalization_148[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_149 (Conv2D)            (None, 12, 12, 160)  179200      ['activation_148[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_149 (Batch  (None, 12, 12, 160)  480        ['conv2d_149[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_149 (Activation)    (None, 12, 12, 160)  0           ['batch_normalization_149[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_145 (Conv2D)            (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_150 (Conv2D)            (None, 12, 12, 160)  179200      ['activation_149[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_145 (Batch  (None, 12, 12, 160)  480        ['conv2d_145[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_150 (Batch  (None, 12, 12, 160)  480        ['conv2d_150[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_145 (Activation)    (None, 12, 12, 160)  0           ['batch_normalization_145[0][0]']\n",
            "                                                                                                  \n",
            " activation_150 (Activation)    (None, 12, 12, 160)  0           ['batch_normalization_150[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_146 (Conv2D)            (None, 12, 12, 160)  179200      ['activation_145[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_151 (Conv2D)            (None, 12, 12, 160)  179200      ['activation_150[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_146 (Batch  (None, 12, 12, 160)  480        ['conv2d_146[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_151 (Batch  (None, 12, 12, 160)  480        ['conv2d_151[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_146 (Activation)    (None, 12, 12, 160)  0           ['batch_normalization_146[0][0]']\n",
            "                                                                                                  \n",
            " activation_151 (Activation)    (None, 12, 12, 160)  0           ['batch_normalization_151[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_14 (AverageP  (None, 12, 12, 768)  0          ['mixed5[0][0]']                 \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_144 (Conv2D)            (None, 12, 12, 192)  147456      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_147 (Conv2D)            (None, 12, 12, 192)  215040      ['activation_146[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_152 (Conv2D)            (None, 12, 12, 192)  215040      ['activation_151[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_153 (Conv2D)            (None, 12, 12, 192)  147456      ['average_pooling2d_14[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_144 (Batch  (None, 12, 12, 192)  576        ['conv2d_144[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_147 (Batch  (None, 12, 12, 192)  576        ['conv2d_147[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_152 (Batch  (None, 12, 12, 192)  576        ['conv2d_152[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_153 (Batch  (None, 12, 12, 192)  576        ['conv2d_153[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_144 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_144[0][0]']\n",
            "                                                                                                  \n",
            " activation_147 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_147[0][0]']\n",
            "                                                                                                  \n",
            " activation_152 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_152[0][0]']\n",
            "                                                                                                  \n",
            " activation_153 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_153[0][0]']\n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)           (None, 12, 12, 768)  0           ['activation_144[0][0]',         \n",
            "                                                                  'activation_147[0][0]',         \n",
            "                                                                  'activation_152[0][0]',         \n",
            "                                                                  'activation_153[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_158 (Conv2D)            (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_158 (Batch  (None, 12, 12, 192)  576        ['conv2d_158[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_158 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_158[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_159 (Conv2D)            (None, 12, 12, 192)  258048      ['activation_158[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_159 (Batch  (None, 12, 12, 192)  576        ['conv2d_159[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_159 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_159[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_155 (Conv2D)            (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_160 (Conv2D)            (None, 12, 12, 192)  258048      ['activation_159[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_155 (Batch  (None, 12, 12, 192)  576        ['conv2d_155[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_160 (Batch  (None, 12, 12, 192)  576        ['conv2d_160[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_155 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_155[0][0]']\n",
            "                                                                                                  \n",
            " activation_160 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_160[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_156 (Conv2D)            (None, 12, 12, 192)  258048      ['activation_155[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_161 (Conv2D)            (None, 12, 12, 192)  258048      ['activation_160[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_156 (Batch  (None, 12, 12, 192)  576        ['conv2d_156[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_161 (Batch  (None, 12, 12, 192)  576        ['conv2d_161[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_156 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_156[0][0]']\n",
            "                                                                                                  \n",
            " activation_161 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_161[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_15 (AverageP  (None, 12, 12, 768)  0          ['mixed6[0][0]']                 \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_154 (Conv2D)            (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_157 (Conv2D)            (None, 12, 12, 192)  258048      ['activation_156[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_162 (Conv2D)            (None, 12, 12, 192)  258048      ['activation_161[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_163 (Conv2D)            (None, 12, 12, 192)  147456      ['average_pooling2d_15[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_154 (Batch  (None, 12, 12, 192)  576        ['conv2d_154[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_157 (Batch  (None, 12, 12, 192)  576        ['conv2d_157[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_162 (Batch  (None, 12, 12, 192)  576        ['conv2d_162[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_163 (Batch  (None, 12, 12, 192)  576        ['conv2d_163[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_154 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_154[0][0]']\n",
            "                                                                                                  \n",
            " activation_157 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_157[0][0]']\n",
            "                                                                                                  \n",
            " activation_162 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_162[0][0]']\n",
            "                                                                                                  \n",
            " activation_163 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_163[0][0]']\n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)           (None, 12, 12, 768)  0           ['activation_154[0][0]',         \n",
            "                                                                  'activation_157[0][0]',         \n",
            "                                                                  'activation_162[0][0]',         \n",
            "                                                                  'activation_163[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_166 (Conv2D)            (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_166 (Batch  (None, 12, 12, 192)  576        ['conv2d_166[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_166 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_166[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_167 (Conv2D)            (None, 12, 12, 192)  258048      ['activation_166[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_167 (Batch  (None, 12, 12, 192)  576        ['conv2d_167[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_167 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_167[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_164 (Conv2D)            (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_168 (Conv2D)            (None, 12, 12, 192)  258048      ['activation_167[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_164 (Batch  (None, 12, 12, 192)  576        ['conv2d_164[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_168 (Batch  (None, 12, 12, 192)  576        ['conv2d_168[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_164 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_164[0][0]']\n",
            "                                                                                                  \n",
            " activation_168 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_168[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_165 (Conv2D)            (None, 5, 5, 320)    552960      ['activation_164[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_169 (Conv2D)            (None, 5, 5, 192)    331776      ['activation_168[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_165 (Batch  (None, 5, 5, 320)   960         ['conv2d_165[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_169 (Batch  (None, 5, 5, 192)   576         ['conv2d_169[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_165 (Activation)    (None, 5, 5, 320)    0           ['batch_normalization_165[0][0]']\n",
            "                                                                                                  \n",
            " activation_169 (Activation)    (None, 5, 5, 192)    0           ['batch_normalization_169[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPooling2D)  (None, 5, 5, 768)   0           ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed8 (Concatenate)           (None, 5, 5, 1280)   0           ['activation_165[0][0]',         \n",
            "                                                                  'activation_169[0][0]',         \n",
            "                                                                  'max_pooling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_174 (Conv2D)            (None, 5, 5, 448)    573440      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_174 (Batch  (None, 5, 5, 448)   1344        ['conv2d_174[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_174 (Activation)    (None, 5, 5, 448)    0           ['batch_normalization_174[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_171 (Conv2D)            (None, 5, 5, 384)    491520      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_175 (Conv2D)            (None, 5, 5, 384)    1548288     ['activation_174[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_171 (Batch  (None, 5, 5, 384)   1152        ['conv2d_171[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_175 (Batch  (None, 5, 5, 384)   1152        ['conv2d_175[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_171 (Activation)    (None, 5, 5, 384)    0           ['batch_normalization_171[0][0]']\n",
            "                                                                                                  \n",
            " activation_175 (Activation)    (None, 5, 5, 384)    0           ['batch_normalization_175[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_172 (Conv2D)            (None, 5, 5, 384)    442368      ['activation_171[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_173 (Conv2D)            (None, 5, 5, 384)    442368      ['activation_171[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_176 (Conv2D)            (None, 5, 5, 384)    442368      ['activation_175[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_177 (Conv2D)            (None, 5, 5, 384)    442368      ['activation_175[0][0]']         \n",
            "                                                                                                  \n",
            " average_pooling2d_16 (AverageP  (None, 5, 5, 1280)  0           ['mixed8[0][0]']                 \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_170 (Conv2D)            (None, 5, 5, 320)    409600      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_172 (Batch  (None, 5, 5, 384)   1152        ['conv2d_172[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_173 (Batch  (None, 5, 5, 384)   1152        ['conv2d_173[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_176 (Batch  (None, 5, 5, 384)   1152        ['conv2d_176[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_177 (Batch  (None, 5, 5, 384)   1152        ['conv2d_177[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_178 (Conv2D)            (None, 5, 5, 192)    245760      ['average_pooling2d_16[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_170 (Batch  (None, 5, 5, 320)   960         ['conv2d_170[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_172 (Activation)    (None, 5, 5, 384)    0           ['batch_normalization_172[0][0]']\n",
            "                                                                                                  \n",
            " activation_173 (Activation)    (None, 5, 5, 384)    0           ['batch_normalization_173[0][0]']\n",
            "                                                                                                  \n",
            " activation_176 (Activation)    (None, 5, 5, 384)    0           ['batch_normalization_176[0][0]']\n",
            "                                                                                                  \n",
            " activation_177 (Activation)    (None, 5, 5, 384)    0           ['batch_normalization_177[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_178 (Batch  (None, 5, 5, 192)   576         ['conv2d_178[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_170 (Activation)    (None, 5, 5, 320)    0           ['batch_normalization_170[0][0]']\n",
            "                                                                                                  \n",
            " mixed9_0 (Concatenate)         (None, 5, 5, 768)    0           ['activation_172[0][0]',         \n",
            "                                                                  'activation_173[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 5, 5, 768)    0           ['activation_176[0][0]',         \n",
            "                                                                  'activation_177[0][0]']         \n",
            "                                                                                                  \n",
            " activation_178 (Activation)    (None, 5, 5, 192)    0           ['batch_normalization_178[0][0]']\n",
            "                                                                                                  \n",
            " mixed9 (Concatenate)           (None, 5, 5, 2048)   0           ['activation_170[0][0]',         \n",
            "                                                                  'mixed9_0[0][0]',               \n",
            "                                                                  'concatenate_2[0][0]',          \n",
            "                                                                  'activation_178[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_183 (Conv2D)            (None, 5, 5, 448)    917504      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_183 (Batch  (None, 5, 5, 448)   1344        ['conv2d_183[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_183 (Activation)    (None, 5, 5, 448)    0           ['batch_normalization_183[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_180 (Conv2D)            (None, 5, 5, 384)    786432      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_184 (Conv2D)            (None, 5, 5, 384)    1548288     ['activation_183[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_180 (Batch  (None, 5, 5, 384)   1152        ['conv2d_180[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_184 (Batch  (None, 5, 5, 384)   1152        ['conv2d_184[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_180 (Activation)    (None, 5, 5, 384)    0           ['batch_normalization_180[0][0]']\n",
            "                                                                                                  \n",
            " activation_184 (Activation)    (None, 5, 5, 384)    0           ['batch_normalization_184[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_181 (Conv2D)            (None, 5, 5, 384)    442368      ['activation_180[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_182 (Conv2D)            (None, 5, 5, 384)    442368      ['activation_180[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_185 (Conv2D)            (None, 5, 5, 384)    442368      ['activation_184[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_186 (Conv2D)            (None, 5, 5, 384)    442368      ['activation_184[0][0]']         \n",
            "                                                                                                  \n",
            " average_pooling2d_17 (AverageP  (None, 5, 5, 2048)  0           ['mixed9[0][0]']                 \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_179 (Conv2D)            (None, 5, 5, 320)    655360      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_181 (Batch  (None, 5, 5, 384)   1152        ['conv2d_181[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_182 (Batch  (None, 5, 5, 384)   1152        ['conv2d_182[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_185 (Batch  (None, 5, 5, 384)   1152        ['conv2d_185[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_186 (Batch  (None, 5, 5, 384)   1152        ['conv2d_186[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_187 (Conv2D)            (None, 5, 5, 192)    393216      ['average_pooling2d_17[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_179 (Batch  (None, 5, 5, 320)   960         ['conv2d_179[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_181 (Activation)    (None, 5, 5, 384)    0           ['batch_normalization_181[0][0]']\n",
            "                                                                                                  \n",
            " activation_182 (Activation)    (None, 5, 5, 384)    0           ['batch_normalization_182[0][0]']\n",
            "                                                                                                  \n",
            " activation_185 (Activation)    (None, 5, 5, 384)    0           ['batch_normalization_185[0][0]']\n",
            "                                                                                                  \n",
            " activation_186 (Activation)    (None, 5, 5, 384)    0           ['batch_normalization_186[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_187 (Batch  (None, 5, 5, 192)   576         ['conv2d_187[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_179 (Activation)    (None, 5, 5, 320)    0           ['batch_normalization_179[0][0]']\n",
            "                                                                                                  \n",
            " mixed9_1 (Concatenate)         (None, 5, 5, 768)    0           ['activation_181[0][0]',         \n",
            "                                                                  'activation_182[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 5, 5, 768)    0           ['activation_185[0][0]',         \n",
            "                                                                  'activation_186[0][0]']         \n",
            "                                                                                                  \n",
            " activation_187 (Activation)    (None, 5, 5, 192)    0           ['batch_normalization_187[0][0]']\n",
            "                                                                                                  \n",
            " mixed10 (Concatenate)          (None, 5, 5, 2048)   0           ['activation_179[0][0]',         \n",
            "                                                                  'mixed9_1[0][0]',               \n",
            "                                                                  'concatenate_3[0][0]',          \n",
            "                                                                  'activation_187[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 21,768,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model architecture"
      ],
      "metadata": {
        "id": "-SXEAs4qdV1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "  mobilenet = MobileNetV2(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(224, 224, 3)\n",
        "  )\n",
        "  inception = InceptionV3(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(224, 224, 3)\n",
        "  )\n",
        "  for layer in inception.layers[:-12]:\n",
        "    layer.trainable = False\n",
        "  x = inception.layers[-1].output\n",
        "  x = tf.keras.layers.Flatten()(x)\n",
        "  x = tf.keras.layers.Dense(\n",
        "    1024,\n",
        "    activation=\"relu\"\n",
        "  )(x)\n",
        "  x = tf.keras.layers.Dropout(\n",
        "    0.6\n",
        "  )(x)\n",
        "  x = tf.keras.layers.Dense(\n",
        "    512,\n",
        "    activation=\"relu\"\n",
        "  )(x)\n",
        "  x = tf.keras.layers.Dropout(\n",
        "    0.3\n",
        "  )(x)\n",
        "  x = tf.keras.layers.Dense(\n",
        "    256,\n",
        "    activation=\"relu\"\n",
        "  )(x)\n",
        "  x = tf.keras.layers.Dropout(\n",
        "    0.2\n",
        "  )(x)\n",
        "  res = tf.keras.layers.Dense(\n",
        "    7,\n",
        "    activation=\"softmax\"\n",
        "  )(x)\n",
        "  return tf.keras.Model(\n",
        "    inputs=inception.input,\n",
        "    outputs=res\n",
        "  )"
      ],
      "metadata": {
        "id": "-DDftZFnMQqs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "build_model().summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQXZNEZPPl37",
        "outputId": "a539c7c2-aacf-4c53-f7d3-7c6ca75f98ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 0s 0us/step\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 111, 111, 32  864         ['input_2[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 111, 111, 32  96         ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 111, 111, 32  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 109, 109, 32  9216        ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 109, 109, 32  96         ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 109, 109, 32  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 109, 109, 64  18432       ['activation_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 109, 109, 64  192        ['conv2d_2[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 109, 109, 64  0           ['batch_normalization_2[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 54, 54, 64)   0           ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 54, 54, 80)   5120        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 54, 54, 80)  240         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 54, 54, 80)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 52, 52, 192)  138240      ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 52, 52, 192)  576        ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 52, 52, 192)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 192)  0          ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 25, 25, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 25, 25, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 25, 25, 96)   55296       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 25, 25, 48)  144         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 25, 25, 96)  288         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 25, 25, 48)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 25, 25, 96)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 25, 25, 192)  0          ['max_pooling2d_1[0][0]']        \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 25, 25, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 25, 25, 64)   76800       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 25, 25, 32)   6144        ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 25, 25, 96)  288         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 25, 25, 32)  96          ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 25, 25, 32)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)           (None, 25, 25, 256)  0           ['activation_5[0][0]',           \n",
            "                                                                  'activation_7[0][0]',           \n",
            "                                                                  'activation_10[0][0]',          \n",
            "                                                                  'activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 25, 25, 64)  192         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 25, 25, 48)   12288       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 25, 25, 48)  144         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 25, 25, 96)  288         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 25, 25, 48)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 25, 25, 256)  0          ['mixed0[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 25, 25, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 25, 25, 64)  192         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 25, 25, 64)  192         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 25, 25, 96)  288         ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 25, 25, 64)  192         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)           (None, 25, 25, 288)  0           ['activation_12[0][0]',          \n",
            "                                                                  'activation_14[0][0]',          \n",
            "                                                                  'activation_17[0][0]',          \n",
            "                                                                  'activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 25, 25, 64)  192         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 25, 25, 48)   13824       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 25, 25, 48)  144         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 25, 25, 96)  288         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 25, 25, 48)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 25, 25, 288)  0          ['mixed1[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 25, 25, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 25, 25, 64)  192         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 25, 25, 64)  192         ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 25, 25, 96)  288         ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 25, 25, 64)  192         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)           (None, 25, 25, 288)  0           ['activation_19[0][0]',          \n",
            "                                                                  'activation_21[0][0]',          \n",
            "                                                                  'activation_24[0][0]',          \n",
            "                                                                  'activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 25, 25, 64)  192         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 25, 25, 96)  288         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 12, 12, 384)  995328      ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 12, 12, 96)   82944       ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 12, 12, 384)  1152       ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 12, 12, 96)  288         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 12, 12, 384)  0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 12, 12, 96)   0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 288)  0          ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)           (None, 12, 12, 768)  0           ['activation_26[0][0]',          \n",
            "                                                                  'activation_29[0][0]',          \n",
            "                                                                  'max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 12, 12, 128)  384        ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 12, 12, 128)  384        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 12, 12, 128)  384        ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 12, 12, 128)  384        ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 12, 12, 128)  384        ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 12, 12, 128)  384        ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (AveragePo  (None, 12, 12, 768)  0          ['mixed3[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 12, 12, 192)  576        ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 12, 12, 192)  576        ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 12, 12, 192)  576        ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 12, 12, 192)  576        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)           (None, 12, 12, 768)  0           ['activation_30[0][0]',          \n",
            "                                                                  'activation_33[0][0]',          \n",
            "                                                                  'activation_38[0][0]',          \n",
            "                                                                  'activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 12, 12, 160)  480        ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 12, 12, 160)  480        ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 12, 12, 160)  480        ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 12, 12, 160)  480        ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 12, 12, 160)  480        ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 12, 12, 160)  480        ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (AveragePo  (None, 12, 12, 768)  0          ['mixed4[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 12, 12, 192)  576        ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 12, 12, 192)  576        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 12, 12, 192)  576        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 12, 12, 192)  576        ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)           (None, 12, 12, 768)  0           ['activation_40[0][0]',          \n",
            "                                                                  'activation_43[0][0]',          \n",
            "                                                                  'activation_48[0][0]',          \n",
            "                                                                  'activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 12, 12, 160)  480        ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_54[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 12, 12, 160)  480        ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_55[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 12, 12, 160)  480        ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 12, 12, 160)  480        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_51[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_56[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 12, 12, 160)  480        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 12, 12, 160)  480        ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_5 (AveragePo  (None, 12, 12, 768)  0          ['mixed5[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_52[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 12, 12, 192)  576        ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 12, 12, 192)  576        ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 12, 12, 192)  576        ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 12, 12, 192)  576        ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)           (None, 12, 12, 768)  0           ['activation_50[0][0]',          \n",
            "                                                                  'activation_53[0][0]',          \n",
            "                                                                  'activation_58[0][0]',          \n",
            "                                                                  'activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 12, 12, 192)  576        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_64[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 12, 12, 192)  576        ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_65[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 12, 12, 192)  576        ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 12, 12, 192)  576        ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_61[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_66[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 12, 12, 192)  576        ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 12, 12, 192)  576        ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (AveragePo  (None, 12, 12, 768)  0          ['mixed6[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_67[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 12, 12, 192)  576        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 12, 12, 192)  576        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 12, 12, 192)  576        ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 12, 12, 192)  576        ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " activation_69 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)           (None, 12, 12, 768)  0           ['activation_60[0][0]',          \n",
            "                                                                  'activation_63[0][0]',          \n",
            "                                                                  'activation_68[0][0]',          \n",
            "                                                                  'activation_69[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 12, 12, 192)  576        ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_72 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_72[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 12, 12, 192)  576        ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_73 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_73[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_73[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 12, 12, 192)  576        ['conv2d_70[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 12, 12, 192)  576        ['conv2d_74[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_70 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " activation_74 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 5, 5, 320)    552960      ['activation_70[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 5, 5, 192)    331776      ['activation_74[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 5, 5, 320)   960         ['conv2d_71[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 5, 5, 192)   576         ['conv2d_75[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_71 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " activation_75 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 768)   0           ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed8 (Concatenate)           (None, 5, 5, 1280)   0           ['activation_71[0][0]',          \n",
            "                                                                  'activation_75[0][0]',          \n",
            "                                                                  'max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 5, 5, 448)    573440      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 5, 5, 448)   1344        ['conv2d_80[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_80 (Activation)     (None, 5, 5, 448)    0           ['batch_normalization_80[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 5, 5, 384)    491520      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 5, 5, 384)    1548288     ['activation_80[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_77[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_81[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_77 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_77[0][0]'] \n",
            "                                                                                                  \n",
            " activation_81 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_81[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_7 (AveragePo  (None, 5, 5, 1280)  0           ['mixed8[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 5, 5, 320)    409600      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_78[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_79[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_82[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_83[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 5, 5, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 5, 5, 320)   960         ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_78 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_78[0][0]'] \n",
            "                                                                                                  \n",
            " activation_79 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_79[0][0]'] \n",
            "                                                                                                  \n",
            " activation_82 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_82[0][0]'] \n",
            "                                                                                                  \n",
            " activation_83 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_83[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 5, 5, 192)   576         ['conv2d_84[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_76 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_76[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_0 (Concatenate)         (None, 5, 5, 768)    0           ['activation_78[0][0]',          \n",
            "                                                                  'activation_79[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 5, 5, 768)    0           ['activation_82[0][0]',          \n",
            "                                                                  'activation_83[0][0]']          \n",
            "                                                                                                  \n",
            " activation_84 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9 (Concatenate)           (None, 5, 5, 2048)   0           ['activation_76[0][0]',          \n",
            "                                                                  'mixed9_0[0][0]',               \n",
            "                                                                  'concatenate[0][0]',            \n",
            "                                                                  'activation_84[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 5, 5, 448)    917504      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 5, 5, 448)   1344        ['conv2d_89[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_89 (Activation)     (None, 5, 5, 448)    0           ['batch_normalization_89[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 5, 5, 384)    786432      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 5, 5, 384)    1548288     ['activation_89[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_86[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_90[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_86 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_86[0][0]'] \n",
            "                                                                                                  \n",
            " activation_90 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_90[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_8 (AveragePo  (None, 5, 5, 2048)  0           ['mixed9[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 5, 5, 320)    655360      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_87[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_88[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_91[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_92[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 5, 5, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 5, 5, 320)   960         ['conv2d_85[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_87 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_87[0][0]'] \n",
            "                                                                                                  \n",
            " activation_88 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_88[0][0]'] \n",
            "                                                                                                  \n",
            " activation_91 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_91[0][0]'] \n",
            "                                                                                                  \n",
            " activation_92 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_92[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 5, 5, 192)   576         ['conv2d_93[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_85 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_85[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_1 (Concatenate)         (None, 5, 5, 768)    0           ['activation_87[0][0]',          \n",
            "                                                                  'activation_88[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 5, 5, 768)    0           ['activation_91[0][0]',          \n",
            "                                                                  'activation_92[0][0]']          \n",
            "                                                                                                  \n",
            " activation_93 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_93[0][0]'] \n",
            "                                                                                                  \n",
            " mixed10 (Concatenate)          (None, 5, 5, 2048)   0           ['activation_85[0][0]',          \n",
            "                                                                  'mixed9_1[0][0]',               \n",
            "                                                                  'concatenate_1[0][0]',          \n",
            "                                                                  'activation_93[0][0]']          \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 51200)        0           ['mixed10[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1024)         52429824    ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 1024)         0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 512)          524800      ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 512)          0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 256)          131328      ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 256)          0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 7)            1799        ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 74,890,535\n",
            "Trainable params: 53,481,479\n",
            "Non-trainable params: 21,409,056\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define callbacks for model training"
      ],
      "metadata": {
        "id": "G5IDY-kpdchP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# learning_rate_sched_callback = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "#   9.4043e-06,\n",
        "#   decay_steps=20000,\n",
        "#   decay_rate=0.9,\n",
        "#   staircase=True\n",
        "# )\n",
        "\n",
        "early_stop_callback = tf.keras.callbacks.EarlyStopping(\n",
        "  monitor=\"val_accuracy\",\n",
        "  patience=11,\n",
        "  verbose=1\n",
        ")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "  filepath=\"/content/inceptionbb-checkpoints-2/{epoch:02d}.ckpt\",\n",
        "  save_weights_only=True,\n",
        "  monitor=\"val_accuracy\",\n",
        "  mode=\"max\",\n",
        "  save_best_only=True,\n",
        "  verbose=1\n",
        ")\n",
        "\n",
        "# reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "#     monitor=\"val_accuracy\",\n",
        "#     mode=\"auto\",\n",
        "#     factor=0.8,\n",
        "#     patience=2,\n",
        "#     min_delta=0.001,\n",
        "#     verbose=1\n",
        "# )"
      ],
      "metadata": {
        "id": "oB0VbQzwo65P"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build model and load latest checkpoint"
      ],
      "metadata": {
        "id": "mXL6Pxl3dkgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()"
      ],
      "metadata": {
        "id": "U2PddHubojQh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d97e460-d91c-4dd8-db2f-722e28d52bc0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(CKPT_PATH)\n",
        "model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(6.4e-05),\n",
        "  loss=\"categorical_crossentropy\",\n",
        "  metrics=[\"accuracy\"]\n",
        ") "
      ],
      "metadata": {
        "id": "DFuG7ScB3ly6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS7H9tRJzBuj",
        "outputId": "551134b6-e4c8-4075-e97d-118a0336ecea"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model using GPU device"
      ],
      "metadata": {
        "id": "IN7O_J1CdoYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device(\"GPU:0\"):\n",
        "  history = model.fit(\n",
        "    trn_generator,\n",
        "    epochs=180,\n",
        "    verbose=1,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[checkpoint_callback, early_stop_callback]\n",
        "  )\n",
        "\n",
        "acc += history.history[\"accuracy\"]\n",
        "val_acc += history.history[\"val_accuracy\"]\n",
        "loss += history.history[\"loss\"]\n",
        "val_loss += history.history[\"val_loss\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dz8i64snpxLa",
        "outputId": "b9c2bfac-3a65-4b44-d44a-ec11f44f2529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.9091 - accuracy: 0.6608\n",
            "Epoch 1: val_accuracy did not improve from 0.70787\n",
            "11/11 [==============================] - 17s 976ms/step - loss: 0.9091 - accuracy: 0.6608 - val_loss: 0.9253 - val_accuracy: 0.6517\n",
            "Epoch 2/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.8464 - accuracy: 0.7018\n",
            "Epoch 2: val_accuracy did not improve from 0.70787\n",
            "11/11 [==============================] - 9s 782ms/step - loss: 0.8464 - accuracy: 0.7018 - val_loss: 0.9415 - val_accuracy: 0.6629\n",
            "Epoch 3/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.8753 - accuracy: 0.6988\n",
            "Epoch 3: val_accuracy did not improve from 0.70787\n",
            "11/11 [==============================] - 8s 798ms/step - loss: 0.8753 - accuracy: 0.6988 - val_loss: 0.9389 - val_accuracy: 0.6629\n",
            "Epoch 4/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.8427 - accuracy: 0.7193\n",
            "Epoch 4: val_accuracy did not improve from 0.70787\n",
            "11/11 [==============================] - 9s 783ms/step - loss: 0.8427 - accuracy: 0.7193 - val_loss: 0.9373 - val_accuracy: 0.6629\n",
            "Epoch 5/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.8027 - accuracy: 0.7339\n",
            "Epoch 5: val_accuracy did not improve from 0.70787\n",
            "11/11 [==============================] - 7s 676ms/step - loss: 0.8027 - accuracy: 0.7339 - val_loss: 0.9139 - val_accuracy: 0.6629\n",
            "Epoch 6/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.8814 - accuracy: 0.6871\n",
            "Epoch 6: val_accuracy did not improve from 0.70787\n",
            "11/11 [==============================] - 8s 775ms/step - loss: 0.8814 - accuracy: 0.6871 - val_loss: 0.9178 - val_accuracy: 0.6854\n",
            "Epoch 7/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.8152 - accuracy: 0.7368\n",
            "Epoch 7: val_accuracy did not improve from 0.70787\n",
            "11/11 [==============================] - 8s 762ms/step - loss: 0.8152 - accuracy: 0.7368 - val_loss: 0.9221 - val_accuracy: 0.6742\n",
            "Epoch 8/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.7925 - accuracy: 0.7456\n",
            "Epoch 8: val_accuracy did not improve from 0.70787\n",
            "11/11 [==============================] - 7s 669ms/step - loss: 0.7925 - accuracy: 0.7456 - val_loss: 0.9036 - val_accuracy: 0.6742\n",
            "Epoch 9/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.7826 - accuracy: 0.7281\n",
            "Epoch 9: val_accuracy did not improve from 0.70787\n",
            "11/11 [==============================] - 8s 743ms/step - loss: 0.7826 - accuracy: 0.7281 - val_loss: 0.8627 - val_accuracy: 0.6742\n",
            "Epoch 10/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.8413 - accuracy: 0.6901\n",
            "Epoch 10: val_accuracy did not improve from 0.70787\n",
            "11/11 [==============================] - 8s 780ms/step - loss: 0.8413 - accuracy: 0.6901 - val_loss: 0.8783 - val_accuracy: 0.7079\n",
            "Epoch 11/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.7249 - accuracy: 0.7398\n",
            "Epoch 11: val_accuracy did not improve from 0.70787\n",
            "11/11 [==============================] - 8s 726ms/step - loss: 0.7249 - accuracy: 0.7398 - val_loss: 0.8805 - val_accuracy: 0.6629\n",
            "Epoch 12/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.7707 - accuracy: 0.7427\n",
            "Epoch 12: val_accuracy did not improve from 0.70787\n",
            "11/11 [==============================] - 10s 882ms/step - loss: 0.7707 - accuracy: 0.7427 - val_loss: 0.8390 - val_accuracy: 0.6629\n",
            "Epoch 13/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.7077 - accuracy: 0.7485\n",
            "Epoch 13: val_accuracy did not improve from 0.70787\n",
            "11/11 [==============================] - 9s 843ms/step - loss: 0.7077 - accuracy: 0.7485 - val_loss: 0.8583 - val_accuracy: 0.6629\n",
            "Epoch 14/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.7057 - accuracy: 0.7398\n",
            "Epoch 14: val_accuracy did not improve from 0.70787\n",
            "11/11 [==============================] - 8s 747ms/step - loss: 0.7057 - accuracy: 0.7398 - val_loss: 0.9103 - val_accuracy: 0.6292\n",
            "Epoch 15/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.7307 - accuracy: 0.7544\n",
            "Epoch 15: val_accuracy did not improve from 0.70787\n",
            "11/11 [==============================] - 10s 919ms/step - loss: 0.7307 - accuracy: 0.7544 - val_loss: 0.8594 - val_accuracy: 0.6517\n",
            "Epoch 16/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.6853 - accuracy: 0.7602\n",
            "Epoch 16: val_accuracy did not improve from 0.70787\n",
            "11/11 [==============================] - 10s 906ms/step - loss: 0.6853 - accuracy: 0.7602 - val_loss: 0.8149 - val_accuracy: 0.6854\n",
            "Epoch 17/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.6994 - accuracy: 0.7398\n",
            "Epoch 17: val_accuracy improved from 0.70787 to 0.71910, saving model to /content/inceptionbb-checkpoints-2/17.ckpt\n",
            "11/11 [==============================] - 15s 1s/step - loss: 0.6994 - accuracy: 0.7398 - val_loss: 0.8352 - val_accuracy: 0.7191\n",
            "Epoch 18/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.7018 - accuracy: 0.7778\n",
            "Epoch 18: val_accuracy did not improve from 0.71910\n",
            "11/11 [==============================] - 9s 798ms/step - loss: 0.7018 - accuracy: 0.7778 - val_loss: 0.8444 - val_accuracy: 0.6742\n",
            "Epoch 19/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.6942 - accuracy: 0.7544\n",
            "Epoch 19: val_accuracy did not improve from 0.71910\n",
            "11/11 [==============================] - 7s 671ms/step - loss: 0.6942 - accuracy: 0.7544 - val_loss: 0.8673 - val_accuracy: 0.6966\n",
            "Epoch 20/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.6644 - accuracy: 0.7661\n",
            "Epoch 20: val_accuracy did not improve from 0.71910\n",
            "11/11 [==============================] - 8s 778ms/step - loss: 0.6644 - accuracy: 0.7661 - val_loss: 0.8650 - val_accuracy: 0.6742\n",
            "Epoch 21/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.6419 - accuracy: 0.7661\n",
            "Epoch 21: val_accuracy did not improve from 0.71910\n",
            "11/11 [==============================] - 9s 869ms/step - loss: 0.6419 - accuracy: 0.7661 - val_loss: 0.8331 - val_accuracy: 0.6854\n",
            "Epoch 22/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.6123 - accuracy: 0.7807\n",
            "Epoch 22: val_accuracy did not improve from 0.71910\n",
            "11/11 [==============================] - 8s 697ms/step - loss: 0.6123 - accuracy: 0.7807 - val_loss: 0.8209 - val_accuracy: 0.6629\n",
            "Epoch 23/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.7177 - accuracy: 0.7690\n",
            "Epoch 23: val_accuracy did not improve from 0.71910\n",
            "11/11 [==============================] - 9s 792ms/step - loss: 0.7177 - accuracy: 0.7690 - val_loss: 0.8475 - val_accuracy: 0.6854\n",
            "Epoch 24/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.6325 - accuracy: 0.8041\n",
            "Epoch 24: val_accuracy did not improve from 0.71910\n",
            "11/11 [==============================] - 9s 782ms/step - loss: 0.6325 - accuracy: 0.8041 - val_loss: 0.8144 - val_accuracy: 0.6966\n",
            "Epoch 25/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.6081 - accuracy: 0.7515\n",
            "Epoch 25: val_accuracy did not improve from 0.71910\n",
            "11/11 [==============================] - 7s 679ms/step - loss: 0.6081 - accuracy: 0.7515 - val_loss: 0.8092 - val_accuracy: 0.7079\n",
            "Epoch 26/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.6796 - accuracy: 0.7924\n",
            "Epoch 26: val_accuracy did not improve from 0.71910\n",
            "11/11 [==============================] - 8s 676ms/step - loss: 0.6796 - accuracy: 0.7924 - val_loss: 0.8212 - val_accuracy: 0.7079\n",
            "Epoch 27/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.5855 - accuracy: 0.7982\n",
            "Epoch 27: val_accuracy did not improve from 0.71910\n",
            "11/11 [==============================] - 8s 775ms/step - loss: 0.5855 - accuracy: 0.7982 - val_loss: 0.8033 - val_accuracy: 0.6854\n",
            "Epoch 28/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.6215 - accuracy: 0.7836\n",
            "Epoch 28: val_accuracy did not improve from 0.71910\n",
            "11/11 [==============================] - 7s 669ms/step - loss: 0.6215 - accuracy: 0.7836 - val_loss: 0.7935 - val_accuracy: 0.7079\n",
            "Epoch 29/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.6481 - accuracy: 0.7924\n",
            "Epoch 29: val_accuracy did not improve from 0.71910\n",
            "11/11 [==============================] - 9s 755ms/step - loss: 0.6481 - accuracy: 0.7924 - val_loss: 0.7942 - val_accuracy: 0.7079\n",
            "Epoch 30/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.5573 - accuracy: 0.8158\n",
            "Epoch 30: val_accuracy did not improve from 0.71910\n",
            "11/11 [==============================] - 8s 772ms/step - loss: 0.5573 - accuracy: 0.8158 - val_loss: 0.8081 - val_accuracy: 0.7079\n",
            "Epoch 31/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.6186 - accuracy: 0.8129\n",
            "Epoch 31: val_accuracy improved from 0.71910 to 0.74157, saving model to /content/inceptionbb-checkpoints-2/31.ckpt\n",
            "11/11 [==============================] - 12s 1s/step - loss: 0.6186 - accuracy: 0.8129 - val_loss: 0.7887 - val_accuracy: 0.7416\n",
            "Epoch 32/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.5255 - accuracy: 0.8158\n",
            "Epoch 32: val_accuracy did not improve from 0.74157\n",
            "11/11 [==============================] - 8s 673ms/step - loss: 0.5255 - accuracy: 0.8158 - val_loss: 0.7728 - val_accuracy: 0.7416\n",
            "Epoch 33/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.5437 - accuracy: 0.7982\n",
            "Epoch 33: val_accuracy did not improve from 0.74157\n",
            "11/11 [==============================] - 8s 775ms/step - loss: 0.5437 - accuracy: 0.7982 - val_loss: 0.8217 - val_accuracy: 0.7079\n",
            "Epoch 34/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.5524 - accuracy: 0.8187\n",
            "Epoch 34: val_accuracy did not improve from 0.74157\n",
            "11/11 [==============================] - 9s 783ms/step - loss: 0.5524 - accuracy: 0.8187 - val_loss: 0.8380 - val_accuracy: 0.7079\n",
            "Epoch 35/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.5781 - accuracy: 0.7778\n",
            "Epoch 35: val_accuracy did not improve from 0.74157\n",
            "11/11 [==============================] - 9s 802ms/step - loss: 0.5781 - accuracy: 0.7778 - val_loss: 0.8699 - val_accuracy: 0.7191\n",
            "Epoch 36/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.5254 - accuracy: 0.8129\n",
            "Epoch 36: val_accuracy did not improve from 0.74157\n",
            "11/11 [==============================] - 9s 869ms/step - loss: 0.5254 - accuracy: 0.8129 - val_loss: 0.8256 - val_accuracy: 0.7303\n",
            "Epoch 37/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.5428 - accuracy: 0.8216\n",
            "Epoch 37: val_accuracy improved from 0.74157 to 0.75281, saving model to /content/inceptionbb-checkpoints-2/37.ckpt\n",
            "11/11 [==============================] - 18s 2s/step - loss: 0.5428 - accuracy: 0.8216 - val_loss: 0.8316 - val_accuracy: 0.7528\n",
            "Epoch 38/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4643 - accuracy: 0.8480\n",
            "Epoch 38: val_accuracy did not improve from 0.75281\n",
            "11/11 [==============================] - 9s 799ms/step - loss: 0.4643 - accuracy: 0.8480 - val_loss: 0.8458 - val_accuracy: 0.6966\n",
            "Epoch 39/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4635 - accuracy: 0.8421\n",
            "Epoch 39: val_accuracy did not improve from 0.75281\n",
            "11/11 [==============================] - 9s 792ms/step - loss: 0.4635 - accuracy: 0.8421 - val_loss: 0.7651 - val_accuracy: 0.7416\n",
            "Epoch 40/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.5098 - accuracy: 0.8187\n",
            "Epoch 40: val_accuracy did not improve from 0.75281\n",
            "11/11 [==============================] - 8s 680ms/step - loss: 0.5098 - accuracy: 0.8187 - val_loss: 0.7380 - val_accuracy: 0.7416\n",
            "Epoch 41/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4097 - accuracy: 0.8684\n",
            "Epoch 41: val_accuracy did not improve from 0.75281\n",
            "11/11 [==============================] - 9s 781ms/step - loss: 0.4097 - accuracy: 0.8684 - val_loss: 0.7875 - val_accuracy: 0.7191\n",
            "Epoch 42/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4771 - accuracy: 0.8538\n",
            "Epoch 42: val_accuracy did not improve from 0.75281\n",
            "11/11 [==============================] - 9s 829ms/step - loss: 0.4771 - accuracy: 0.8538 - val_loss: 0.7818 - val_accuracy: 0.7528\n",
            "Epoch 43/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4503 - accuracy: 0.8421\n",
            "Epoch 43: val_accuracy did not improve from 0.75281\n",
            "11/11 [==============================] - 7s 674ms/step - loss: 0.4503 - accuracy: 0.8421 - val_loss: 0.7793 - val_accuracy: 0.7191\n",
            "Epoch 44/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4304 - accuracy: 0.8538\n",
            "Epoch 44: val_accuracy did not improve from 0.75281\n",
            "11/11 [==============================] - 7s 674ms/step - loss: 0.4304 - accuracy: 0.8538 - val_loss: 0.7554 - val_accuracy: 0.7079\n",
            "Epoch 45/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4213 - accuracy: 0.8772\n",
            "Epoch 45: val_accuracy did not improve from 0.75281\n",
            "11/11 [==============================] - 10s 940ms/step - loss: 0.4213 - accuracy: 0.8772 - val_loss: 0.7289 - val_accuracy: 0.7528\n",
            "Epoch 46/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4804 - accuracy: 0.8392\n",
            "Epoch 46: val_accuracy did not improve from 0.75281\n",
            "11/11 [==============================] - 9s 820ms/step - loss: 0.4804 - accuracy: 0.8392 - val_loss: 0.7533 - val_accuracy: 0.7191\n",
            "Epoch 47/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4150 - accuracy: 0.8509\n",
            "Epoch 47: val_accuracy did not improve from 0.75281\n",
            "11/11 [==============================] - 7s 669ms/step - loss: 0.4150 - accuracy: 0.8509 - val_loss: 0.7790 - val_accuracy: 0.7416\n",
            "Epoch 48/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4316 - accuracy: 0.8626\n",
            "Epoch 48: val_accuracy did not improve from 0.75281\n",
            "11/11 [==============================] - 9s 786ms/step - loss: 0.4316 - accuracy: 0.8626 - val_loss: 0.7794 - val_accuracy: 0.7528\n",
            "Epoch 49/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4259 - accuracy: 0.8713\n",
            "Epoch 49: val_accuracy improved from 0.75281 to 0.79775, saving model to /content/inceptionbb-checkpoints-2/49.ckpt\n",
            "11/11 [==============================] - 16s 2s/step - loss: 0.4259 - accuracy: 0.8713 - val_loss: 0.7797 - val_accuracy: 0.7978\n",
            "Epoch 50/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4451 - accuracy: 0.8596\n",
            "Epoch 50: val_accuracy did not improve from 0.79775\n",
            "11/11 [==============================] - 9s 783ms/step - loss: 0.4451 - accuracy: 0.8596 - val_loss: 0.7601 - val_accuracy: 0.7753\n",
            "Epoch 51/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4743 - accuracy: 0.8216\n",
            "Epoch 51: val_accuracy did not improve from 0.79775\n",
            "11/11 [==============================] - 8s 754ms/step - loss: 0.4743 - accuracy: 0.8216 - val_loss: 0.7760 - val_accuracy: 0.7640\n",
            "Epoch 52/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4641 - accuracy: 0.8567\n",
            "Epoch 52: val_accuracy did not improve from 0.79775\n",
            "11/11 [==============================] - 9s 770ms/step - loss: 0.4641 - accuracy: 0.8567 - val_loss: 0.7301 - val_accuracy: 0.7528\n",
            "Epoch 53/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4278 - accuracy: 0.8538\n",
            "Epoch 53: val_accuracy did not improve from 0.79775\n",
            "11/11 [==============================] - 10s 961ms/step - loss: 0.4278 - accuracy: 0.8538 - val_loss: 0.7264 - val_accuracy: 0.7865\n",
            "Epoch 54/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4023 - accuracy: 0.8684\n",
            "Epoch 54: val_accuracy did not improve from 0.79775\n",
            "11/11 [==============================] - 10s 963ms/step - loss: 0.4023 - accuracy: 0.8684 - val_loss: 0.7748 - val_accuracy: 0.7303\n",
            "Epoch 55/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4301 - accuracy: 0.8626\n",
            "Epoch 55: val_accuracy did not improve from 0.79775\n",
            "11/11 [==============================] - 11s 997ms/step - loss: 0.4301 - accuracy: 0.8626 - val_loss: 0.7538 - val_accuracy: 0.7640\n",
            "Epoch 56/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4079 - accuracy: 0.8684\n",
            "Epoch 56: val_accuracy did not improve from 0.79775\n",
            "11/11 [==============================] - 9s 782ms/step - loss: 0.4079 - accuracy: 0.8684 - val_loss: 0.7238 - val_accuracy: 0.7640\n",
            "Epoch 57/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4597 - accuracy: 0.8684\n",
            "Epoch 57: val_accuracy did not improve from 0.79775\n",
            "11/11 [==============================] - 9s 842ms/step - loss: 0.4597 - accuracy: 0.8684 - val_loss: 0.7969 - val_accuracy: 0.7528\n",
            "Epoch 58/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3896 - accuracy: 0.8772\n",
            "Epoch 58: val_accuracy did not improve from 0.79775\n",
            "11/11 [==============================] - 8s 746ms/step - loss: 0.3896 - accuracy: 0.8772 - val_loss: 0.7433 - val_accuracy: 0.7753\n",
            "Epoch 59/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3784 - accuracy: 0.8743\n",
            "Epoch 59: val_accuracy did not improve from 0.79775\n",
            "11/11 [==============================] - 8s 697ms/step - loss: 0.3784 - accuracy: 0.8743 - val_loss: 0.7173 - val_accuracy: 0.7753\n",
            "Epoch 60/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3642 - accuracy: 0.8684\n",
            "Epoch 60: val_accuracy did not improve from 0.79775\n",
            "11/11 [==============================] - 8s 778ms/step - loss: 0.3642 - accuracy: 0.8684 - val_loss: 0.7174 - val_accuracy: 0.7528\n",
            "Epoch 61/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3210 - accuracy: 0.8947\n",
            "Epoch 61: val_accuracy did not improve from 0.79775\n",
            "11/11 [==============================] - 9s 790ms/step - loss: 0.3210 - accuracy: 0.8947 - val_loss: 0.7128 - val_accuracy: 0.7753\n",
            "Epoch 62/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3686 - accuracy: 0.9064\n",
            "Epoch 62: val_accuracy did not improve from 0.79775\n",
            "11/11 [==============================] - 8s 687ms/step - loss: 0.3686 - accuracy: 0.9064 - val_loss: 0.6906 - val_accuracy: 0.7865\n",
            "Epoch 63/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3086 - accuracy: 0.8918\n",
            "Epoch 63: val_accuracy did not improve from 0.79775\n",
            "11/11 [==============================] - 9s 794ms/step - loss: 0.3086 - accuracy: 0.8918 - val_loss: 0.7305 - val_accuracy: 0.7865\n",
            "Epoch 64/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3356 - accuracy: 0.8713\n",
            "Epoch 64: val_accuracy did not improve from 0.79775\n",
            "11/11 [==============================] - 8s 770ms/step - loss: 0.3356 - accuracy: 0.8713 - val_loss: 0.6998 - val_accuracy: 0.7753\n",
            "Epoch 65/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3665 - accuracy: 0.8918\n",
            "Epoch 65: val_accuracy did not improve from 0.79775\n",
            "11/11 [==============================] - 8s 685ms/step - loss: 0.3665 - accuracy: 0.8918 - val_loss: 0.7285 - val_accuracy: 0.7753\n",
            "Epoch 66/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3413 - accuracy: 0.8830\n",
            "Epoch 66: val_accuracy improved from 0.79775 to 0.80899, saving model to /content/inceptionbb-checkpoints-2/66.ckpt\n",
            "11/11 [==============================] - 12s 1s/step - loss: 0.3413 - accuracy: 0.8830 - val_loss: 0.7079 - val_accuracy: 0.8090\n",
            "Epoch 67/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3425 - accuracy: 0.8743\n",
            "Epoch 67: val_accuracy did not improve from 0.80899\n",
            "11/11 [==============================] - 9s 788ms/step - loss: 0.3425 - accuracy: 0.8743 - val_loss: 0.7274 - val_accuracy: 0.7978\n",
            "Epoch 68/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3560 - accuracy: 0.8947\n",
            "Epoch 68: val_accuracy did not improve from 0.80899\n",
            "11/11 [==============================] - 8s 752ms/step - loss: 0.3560 - accuracy: 0.8947 - val_loss: 0.7110 - val_accuracy: 0.7753\n",
            "Epoch 69/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2804 - accuracy: 0.8977\n",
            "Epoch 69: val_accuracy improved from 0.80899 to 0.82022, saving model to /content/inceptionbb-checkpoints-2/69.ckpt\n",
            "11/11 [==============================] - 15s 1s/step - loss: 0.2804 - accuracy: 0.8977 - val_loss: 0.7031 - val_accuracy: 0.8202\n",
            "Epoch 70/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3324 - accuracy: 0.8743\n",
            "Epoch 70: val_accuracy improved from 0.82022 to 0.83146, saving model to /content/inceptionbb-checkpoints-2/70.ckpt\n",
            "11/11 [==============================] - 18s 2s/step - loss: 0.3324 - accuracy: 0.8743 - val_loss: 0.7133 - val_accuracy: 0.8315\n",
            "Epoch 71/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3306 - accuracy: 0.8860\n",
            "Epoch 71: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 10s 903ms/step - loss: 0.3306 - accuracy: 0.8860 - val_loss: 0.7345 - val_accuracy: 0.7978\n",
            "Epoch 72/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2762 - accuracy: 0.9035\n",
            "Epoch 72: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 12s 1s/step - loss: 0.2762 - accuracy: 0.9035 - val_loss: 0.7430 - val_accuracy: 0.8202\n",
            "Epoch 73/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2755 - accuracy: 0.9181\n",
            "Epoch 73: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 845ms/step - loss: 0.2755 - accuracy: 0.9181 - val_loss: 0.7204 - val_accuracy: 0.7640\n",
            "Epoch 74/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2987 - accuracy: 0.8977\n",
            "Epoch 74: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 692ms/step - loss: 0.2987 - accuracy: 0.8977 - val_loss: 0.7247 - val_accuracy: 0.8090\n",
            "Epoch 75/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2697 - accuracy: 0.9006\n",
            "Epoch 75: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 790ms/step - loss: 0.2697 - accuracy: 0.9006 - val_loss: 0.8194 - val_accuracy: 0.7416\n",
            "Epoch 76/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2608 - accuracy: 0.9211\n",
            "Epoch 76: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 751ms/step - loss: 0.2608 - accuracy: 0.9211 - val_loss: 0.8405 - val_accuracy: 0.7528\n",
            "Epoch 77/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3731 - accuracy: 0.8743\n",
            "Epoch 77: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 694ms/step - loss: 0.3731 - accuracy: 0.8743 - val_loss: 0.7670 - val_accuracy: 0.7528\n",
            "Epoch 78/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2482 - accuracy: 0.9211\n",
            "Epoch 78: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 787ms/step - loss: 0.2482 - accuracy: 0.9211 - val_loss: 0.7294 - val_accuracy: 0.7978\n",
            "Epoch 79/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2416 - accuracy: 0.9123\n",
            "Epoch 79: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 696ms/step - loss: 0.2416 - accuracy: 0.9123 - val_loss: 0.7624 - val_accuracy: 0.7865\n",
            "Epoch 80/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3084 - accuracy: 0.9006\n",
            "Epoch 80: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 769ms/step - loss: 0.3084 - accuracy: 0.9006 - val_loss: 0.7866 - val_accuracy: 0.7865\n",
            "Epoch 81/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2831 - accuracy: 0.9035\n",
            "Epoch 81: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 789ms/step - loss: 0.2831 - accuracy: 0.9035 - val_loss: 0.7807 - val_accuracy: 0.7753\n",
            "Epoch 82/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2926 - accuracy: 0.9181\n",
            "Epoch 82: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 685ms/step - loss: 0.2926 - accuracy: 0.9181 - val_loss: 0.7662 - val_accuracy: 0.7978\n",
            "Epoch 83/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3204 - accuracy: 0.8889\n",
            "Epoch 83: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 791ms/step - loss: 0.3204 - accuracy: 0.8889 - val_loss: 0.8572 - val_accuracy: 0.7528\n",
            "Epoch 84/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2954 - accuracy: 0.9064\n",
            "Epoch 84: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 761ms/step - loss: 0.2954 - accuracy: 0.9064 - val_loss: 0.7924 - val_accuracy: 0.7753\n",
            "Epoch 85/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2363 - accuracy: 0.9181\n",
            "Epoch 85: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 698ms/step - loss: 0.2363 - accuracy: 0.9181 - val_loss: 0.7754 - val_accuracy: 0.7640\n",
            "Epoch 86/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3146 - accuracy: 0.9094\n",
            "Epoch 86: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 10s 902ms/step - loss: 0.3146 - accuracy: 0.9094 - val_loss: 0.7830 - val_accuracy: 0.7753\n",
            "Epoch 87/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3051 - accuracy: 0.9064\n",
            "Epoch 87: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 790ms/step - loss: 0.3051 - accuracy: 0.9064 - val_loss: 0.7814 - val_accuracy: 0.7640\n",
            "Epoch 88/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2921 - accuracy: 0.9152\n",
            "Epoch 88: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 702ms/step - loss: 0.2921 - accuracy: 0.9152 - val_loss: 0.7752 - val_accuracy: 0.7865\n",
            "Epoch 89/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2799 - accuracy: 0.9152\n",
            "Epoch 89: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 10s 927ms/step - loss: 0.2799 - accuracy: 0.9152 - val_loss: 0.7410 - val_accuracy: 0.7640\n",
            "Epoch 90/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2683 - accuracy: 0.9357\n",
            "Epoch 90: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 10s 907ms/step - loss: 0.2683 - accuracy: 0.9357 - val_loss: 0.7569 - val_accuracy: 0.7865\n",
            "Epoch 91/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1923 - accuracy: 0.9532\n",
            "Epoch 91: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 809ms/step - loss: 0.1923 - accuracy: 0.9532 - val_loss: 0.7786 - val_accuracy: 0.7753\n",
            "Epoch 92/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2321 - accuracy: 0.9327\n",
            "Epoch 92: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 804ms/step - loss: 0.2321 - accuracy: 0.9327 - val_loss: 0.8338 - val_accuracy: 0.7865\n",
            "Epoch 93/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2441 - accuracy: 0.9327\n",
            "Epoch 93: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 10s 900ms/step - loss: 0.2441 - accuracy: 0.9327 - val_loss: 0.8714 - val_accuracy: 0.7528\n",
            "Epoch 94/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2766 - accuracy: 0.9181\n",
            "Epoch 94: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 788ms/step - loss: 0.2766 - accuracy: 0.9181 - val_loss: 0.8115 - val_accuracy: 0.7865\n",
            "Epoch 95/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2678 - accuracy: 0.9211\n",
            "Epoch 95: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 717ms/step - loss: 0.2678 - accuracy: 0.9211 - val_loss: 0.7773 - val_accuracy: 0.7978\n",
            "Epoch 96/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1928 - accuracy: 0.9591\n",
            "Epoch 96: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 798ms/step - loss: 0.1928 - accuracy: 0.9591 - val_loss: 0.7922 - val_accuracy: 0.7865\n",
            "Epoch 97/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2583 - accuracy: 0.9298\n",
            "Epoch 97: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 728ms/step - loss: 0.2583 - accuracy: 0.9298 - val_loss: 0.7746 - val_accuracy: 0.7978\n",
            "Epoch 98/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2044 - accuracy: 0.9269\n",
            "Epoch 98: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 686ms/step - loss: 0.2044 - accuracy: 0.9269 - val_loss: 0.7775 - val_accuracy: 0.8090\n",
            "Epoch 99/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2406 - accuracy: 0.9181\n",
            "Epoch 99: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 685ms/step - loss: 0.2406 - accuracy: 0.9181 - val_loss: 0.7680 - val_accuracy: 0.7978\n",
            "Epoch 100/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2671 - accuracy: 0.9211\n",
            "Epoch 100: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 788ms/step - loss: 0.2671 - accuracy: 0.9211 - val_loss: 0.7441 - val_accuracy: 0.8202\n",
            "Epoch 101/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1914 - accuracy: 0.9298\n",
            "Epoch 101: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 784ms/step - loss: 0.1914 - accuracy: 0.9298 - val_loss: 0.7569 - val_accuracy: 0.8090\n",
            "Epoch 102/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2378 - accuracy: 0.9152\n",
            "Epoch 102: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 723ms/step - loss: 0.2378 - accuracy: 0.9152 - val_loss: 0.7594 - val_accuracy: 0.8315\n",
            "Epoch 103/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2497 - accuracy: 0.9298\n",
            "Epoch 103: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 794ms/step - loss: 0.2497 - accuracy: 0.9298 - val_loss: 0.8191 - val_accuracy: 0.7978\n",
            "Epoch 104/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2084 - accuracy: 0.9327\n",
            "Epoch 104: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 779ms/step - loss: 0.2084 - accuracy: 0.9327 - val_loss: 0.8095 - val_accuracy: 0.7753\n",
            "Epoch 105/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2139 - accuracy: 0.9298\n",
            "Epoch 105: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 686ms/step - loss: 0.2139 - accuracy: 0.9298 - val_loss: 0.8351 - val_accuracy: 0.7865\n",
            "Epoch 106/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3291 - accuracy: 0.8801\n",
            "Epoch 106: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 783ms/step - loss: 0.3291 - accuracy: 0.8801 - val_loss: 0.8372 - val_accuracy: 0.7753\n",
            "Epoch 107/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2360 - accuracy: 0.9240\n",
            "Epoch 107: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 786ms/step - loss: 0.2360 - accuracy: 0.9240 - val_loss: 0.8349 - val_accuracy: 0.7978\n",
            "Epoch 108/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2306 - accuracy: 0.9357\n",
            "Epoch 108: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 710ms/step - loss: 0.2306 - accuracy: 0.9357 - val_loss: 0.8366 - val_accuracy: 0.7865\n",
            "Epoch 109/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2603 - accuracy: 0.9211\n",
            "Epoch 109: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 10s 839ms/step - loss: 0.2603 - accuracy: 0.9211 - val_loss: 0.8075 - val_accuracy: 0.7865\n",
            "Epoch 110/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1830 - accuracy: 0.9532\n",
            "Epoch 110: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 10s 918ms/step - loss: 0.1830 - accuracy: 0.9532 - val_loss: 0.8522 - val_accuracy: 0.7753\n",
            "Epoch 111/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3106 - accuracy: 0.9006\n",
            "Epoch 111: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 10s 880ms/step - loss: 0.3106 - accuracy: 0.9006 - val_loss: 0.9717 - val_accuracy: 0.7416\n",
            "Epoch 112/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2835 - accuracy: 0.8918\n",
            "Epoch 112: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 752ms/step - loss: 0.2835 - accuracy: 0.8918 - val_loss: 0.8486 - val_accuracy: 0.7640\n",
            "Epoch 113/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1828 - accuracy: 0.9415\n",
            "Epoch 113: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 870ms/step - loss: 0.1828 - accuracy: 0.9415 - val_loss: 0.7901 - val_accuracy: 0.7978\n",
            "Epoch 114/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2248 - accuracy: 0.9298\n",
            "Epoch 114: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 770ms/step - loss: 0.2248 - accuracy: 0.9298 - val_loss: 0.8337 - val_accuracy: 0.7978\n",
            "Epoch 115/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2040 - accuracy: 0.9357\n",
            "Epoch 115: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 687ms/step - loss: 0.2040 - accuracy: 0.9357 - val_loss: 0.8779 - val_accuracy: 0.7978\n",
            "Epoch 116/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2147 - accuracy: 0.9240\n",
            "Epoch 116: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 784ms/step - loss: 0.2147 - accuracy: 0.9240 - val_loss: 0.8160 - val_accuracy: 0.7865\n",
            "Epoch 117/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2150 - accuracy: 0.9152\n",
            "Epoch 117: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 778ms/step - loss: 0.2150 - accuracy: 0.9152 - val_loss: 0.7908 - val_accuracy: 0.7978\n",
            "Epoch 118/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2568 - accuracy: 0.9211\n",
            "Epoch 118: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 827ms/step - loss: 0.2568 - accuracy: 0.9211 - val_loss: 0.7533 - val_accuracy: 0.7978\n",
            "Epoch 119/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2303 - accuracy: 0.9386\n",
            "Epoch 119: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 688ms/step - loss: 0.2303 - accuracy: 0.9386 - val_loss: 0.7609 - val_accuracy: 0.7978\n",
            "Epoch 120/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1958 - accuracy: 0.9415\n",
            "Epoch 120: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 688ms/step - loss: 0.1958 - accuracy: 0.9415 - val_loss: 0.8147 - val_accuracy: 0.7528\n",
            "Epoch 121/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1816 - accuracy: 0.9503\n",
            "Epoch 121: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 796ms/step - loss: 0.1816 - accuracy: 0.9503 - val_loss: 0.8129 - val_accuracy: 0.7978\n",
            "Epoch 122/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1062 - accuracy: 0.9678\n",
            "Epoch 122: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 7s 690ms/step - loss: 0.1062 - accuracy: 0.9678 - val_loss: 0.8068 - val_accuracy: 0.7753\n",
            "Epoch 123/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1771 - accuracy: 0.9532\n",
            "Epoch 123: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 770ms/step - loss: 0.1771 - accuracy: 0.9532 - val_loss: 0.8621 - val_accuracy: 0.7528\n",
            "Epoch 124/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2370 - accuracy: 0.9269\n",
            "Epoch 124: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 790ms/step - loss: 0.2370 - accuracy: 0.9269 - val_loss: 0.8770 - val_accuracy: 0.7528\n",
            "Epoch 125/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2115 - accuracy: 0.9444\n",
            "Epoch 125: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 740ms/step - loss: 0.2115 - accuracy: 0.9444 - val_loss: 0.9177 - val_accuracy: 0.7640\n",
            "Epoch 126/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1657 - accuracy: 0.9591\n",
            "Epoch 126: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 682ms/step - loss: 0.1657 - accuracy: 0.9591 - val_loss: 0.8074 - val_accuracy: 0.7753\n",
            "Epoch 127/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2146 - accuracy: 0.9415\n",
            "Epoch 127: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 740ms/step - loss: 0.2146 - accuracy: 0.9415 - val_loss: 0.8526 - val_accuracy: 0.7640\n",
            "Epoch 128/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2238 - accuracy: 0.9269\n",
            "Epoch 128: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 10s 874ms/step - loss: 0.2238 - accuracy: 0.9269 - val_loss: 0.8687 - val_accuracy: 0.7640\n",
            "Epoch 129/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1827 - accuracy: 0.9444\n",
            "Epoch 129: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 861ms/step - loss: 0.1827 - accuracy: 0.9444 - val_loss: 0.8717 - val_accuracy: 0.7640\n",
            "Epoch 130/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1820 - accuracy: 0.9386\n",
            "Epoch 130: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 822ms/step - loss: 0.1820 - accuracy: 0.9386 - val_loss: 0.8198 - val_accuracy: 0.7978\n",
            "Epoch 131/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1569 - accuracy: 0.9561\n",
            "Epoch 131: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 808ms/step - loss: 0.1569 - accuracy: 0.9561 - val_loss: 0.7901 - val_accuracy: 0.7753\n",
            "Epoch 132/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2716 - accuracy: 0.9152\n",
            "Epoch 132: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 10s 885ms/step - loss: 0.2716 - accuracy: 0.9152 - val_loss: 0.8578 - val_accuracy: 0.7640\n",
            "Epoch 133/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2074 - accuracy: 0.9386\n",
            "Epoch 133: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 813ms/step - loss: 0.2074 - accuracy: 0.9386 - val_loss: 0.9057 - val_accuracy: 0.7528\n",
            "Epoch 134/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1905 - accuracy: 0.9386\n",
            "Epoch 134: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 687ms/step - loss: 0.1905 - accuracy: 0.9386 - val_loss: 0.8828 - val_accuracy: 0.7640\n",
            "Epoch 135/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1689 - accuracy: 0.9561\n",
            "Epoch 135: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 805ms/step - loss: 0.1689 - accuracy: 0.9561 - val_loss: 0.8921 - val_accuracy: 0.7303\n",
            "Epoch 136/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2146 - accuracy: 0.9357\n",
            "Epoch 136: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 786ms/step - loss: 0.2146 - accuracy: 0.9357 - val_loss: 0.8577 - val_accuracy: 0.7640\n",
            "Epoch 137/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1661 - accuracy: 0.9474\n",
            "Epoch 137: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 690ms/step - loss: 0.1661 - accuracy: 0.9474 - val_loss: 0.8396 - val_accuracy: 0.7865\n",
            "Epoch 138/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1871 - accuracy: 0.9327\n",
            "Epoch 138: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 770ms/step - loss: 0.1871 - accuracy: 0.9327 - val_loss: 0.8412 - val_accuracy: 0.7978\n",
            "Epoch 139/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1767 - accuracy: 0.9503\n",
            "Epoch 139: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 719ms/step - loss: 0.1767 - accuracy: 0.9503 - val_loss: 0.8366 - val_accuracy: 0.7865\n",
            "Epoch 140/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1637 - accuracy: 0.9386\n",
            "Epoch 140: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 669ms/step - loss: 0.1637 - accuracy: 0.9386 - val_loss: 0.8773 - val_accuracy: 0.7865\n",
            "Epoch 141/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2423 - accuracy: 0.9269\n",
            "Epoch 141: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 791ms/step - loss: 0.2423 - accuracy: 0.9269 - val_loss: 0.9817 - val_accuracy: 0.7416\n",
            "Epoch 142/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1667 - accuracy: 0.9503\n",
            "Epoch 142: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 742ms/step - loss: 0.1667 - accuracy: 0.9503 - val_loss: 0.9680 - val_accuracy: 0.7528\n",
            "Epoch 143/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1702 - accuracy: 0.9503\n",
            "Epoch 143: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 709ms/step - loss: 0.1702 - accuracy: 0.9503 - val_loss: 0.9910 - val_accuracy: 0.7191\n",
            "Epoch 144/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2080 - accuracy: 0.9444\n",
            "Epoch 144: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 767ms/step - loss: 0.2080 - accuracy: 0.9444 - val_loss: 0.8572 - val_accuracy: 0.8090\n",
            "Epoch 145/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2627 - accuracy: 0.9327\n",
            "Epoch 145: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 680ms/step - loss: 0.2627 - accuracy: 0.9327 - val_loss: 0.7864 - val_accuracy: 0.7865\n",
            "Epoch 146/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1876 - accuracy: 0.9240\n",
            "Epoch 146: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 868ms/step - loss: 0.1876 - accuracy: 0.9240 - val_loss: 0.8728 - val_accuracy: 0.7416\n",
            "Epoch 147/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1290 - accuracy: 0.9591\n",
            "Epoch 147: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 781ms/step - loss: 0.1290 - accuracy: 0.9591 - val_loss: 0.8884 - val_accuracy: 0.7640\n",
            "Epoch 148/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1031 - accuracy: 0.9678\n",
            "Epoch 148: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 802ms/step - loss: 0.1031 - accuracy: 0.9678 - val_loss: 0.8834 - val_accuracy: 0.7640\n",
            "Epoch 149/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1681 - accuracy: 0.9415\n",
            "Epoch 149: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 797ms/step - loss: 0.1681 - accuracy: 0.9415 - val_loss: 0.8694 - val_accuracy: 0.7528\n",
            "Epoch 150/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2214 - accuracy: 0.9444\n",
            "Epoch 150: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 791ms/step - loss: 0.2214 - accuracy: 0.9444 - val_loss: 0.8782 - val_accuracy: 0.7640\n",
            "Epoch 151/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1616 - accuracy: 0.9503\n",
            "Epoch 151: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 810ms/step - loss: 0.1616 - accuracy: 0.9503 - val_loss: 0.7922 - val_accuracy: 0.7978\n",
            "Epoch 152/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2018 - accuracy: 0.9386\n",
            "Epoch 152: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 855ms/step - loss: 0.2018 - accuracy: 0.9386 - val_loss: 0.8937 - val_accuracy: 0.7303\n",
            "Epoch 153/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2038 - accuracy: 0.9386\n",
            "Epoch 153: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 789ms/step - loss: 0.2038 - accuracy: 0.9386 - val_loss: 0.8194 - val_accuracy: 0.7865\n",
            "Epoch 154/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1900 - accuracy: 0.9444\n",
            "Epoch 154: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 795ms/step - loss: 0.1900 - accuracy: 0.9444 - val_loss: 0.7944 - val_accuracy: 0.7640\n",
            "Epoch 155/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2151 - accuracy: 0.9357\n",
            "Epoch 155: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 7s 678ms/step - loss: 0.2151 - accuracy: 0.9357 - val_loss: 0.8172 - val_accuracy: 0.7753\n",
            "Epoch 156/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1396 - accuracy: 0.9620\n",
            "Epoch 156: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 829ms/step - loss: 0.1396 - accuracy: 0.9620 - val_loss: 0.7866 - val_accuracy: 0.7865\n",
            "Epoch 157/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1591 - accuracy: 0.9591\n",
            "Epoch 157: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 767ms/step - loss: 0.1591 - accuracy: 0.9591 - val_loss: 0.7644 - val_accuracy: 0.7640\n",
            "Epoch 158/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1342 - accuracy: 0.9503\n",
            "Epoch 158: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 709ms/step - loss: 0.1342 - accuracy: 0.9503 - val_loss: 0.7441 - val_accuracy: 0.7865\n",
            "Epoch 159/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1541 - accuracy: 0.9532\n",
            "Epoch 159: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 7s 688ms/step - loss: 0.1541 - accuracy: 0.9532 - val_loss: 0.8011 - val_accuracy: 0.7753\n",
            "Epoch 160/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1519 - accuracy: 0.9532\n",
            "Epoch 160: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 668ms/step - loss: 0.1519 - accuracy: 0.9532 - val_loss: 0.8549 - val_accuracy: 0.7753\n",
            "Epoch 161/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1140 - accuracy: 0.9649\n",
            "Epoch 161: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 776ms/step - loss: 0.1140 - accuracy: 0.9649 - val_loss: 0.8671 - val_accuracy: 0.7865\n",
            "Epoch 162/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1315 - accuracy: 0.9561\n",
            "Epoch 162: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 7s 653ms/step - loss: 0.1315 - accuracy: 0.9561 - val_loss: 0.8615 - val_accuracy: 0.7865\n",
            "Epoch 163/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0869 - accuracy: 0.9737\n",
            "Epoch 163: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 793ms/step - loss: 0.0869 - accuracy: 0.9737 - val_loss: 0.8540 - val_accuracy: 0.7865\n",
            "Epoch 164/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1584 - accuracy: 0.9532\n",
            "Epoch 164: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 757ms/step - loss: 0.1584 - accuracy: 0.9532 - val_loss: 0.8670 - val_accuracy: 0.7640\n",
            "Epoch 165/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1822 - accuracy: 0.9386\n",
            "Epoch 165: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 7s 668ms/step - loss: 0.1822 - accuracy: 0.9386 - val_loss: 0.9401 - val_accuracy: 0.7528\n",
            "Epoch 166/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2345 - accuracy: 0.9444\n",
            "Epoch 166: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 745ms/step - loss: 0.2345 - accuracy: 0.9444 - val_loss: 0.8472 - val_accuracy: 0.7640\n",
            "Epoch 167/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1746 - accuracy: 0.9415\n",
            "Epoch 167: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 795ms/step - loss: 0.1746 - accuracy: 0.9415 - val_loss: 0.9083 - val_accuracy: 0.7640\n",
            "Epoch 168/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1413 - accuracy: 0.9503\n",
            "Epoch 168: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 786ms/step - loss: 0.1413 - accuracy: 0.9503 - val_loss: 0.8089 - val_accuracy: 0.7865\n",
            "Epoch 169/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1294 - accuracy: 0.9620\n",
            "Epoch 169: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 754ms/step - loss: 0.1294 - accuracy: 0.9620 - val_loss: 0.8143 - val_accuracy: 0.7753\n",
            "Epoch 170/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1760 - accuracy: 0.9503\n",
            "Epoch 170: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 10s 893ms/step - loss: 0.1760 - accuracy: 0.9503 - val_loss: 0.8159 - val_accuracy: 0.7640\n",
            "Epoch 171/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1493 - accuracy: 0.9444\n",
            "Epoch 171: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 861ms/step - loss: 0.1493 - accuracy: 0.9444 - val_loss: 0.8240 - val_accuracy: 0.7528\n",
            "Epoch 172/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1749 - accuracy: 0.9327\n",
            "Epoch 172: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 778ms/step - loss: 0.1749 - accuracy: 0.9327 - val_loss: 0.8425 - val_accuracy: 0.7640\n",
            "Epoch 173/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1619 - accuracy: 0.9474\n",
            "Epoch 173: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 790ms/step - loss: 0.1619 - accuracy: 0.9474 - val_loss: 0.8733 - val_accuracy: 0.7753\n",
            "Epoch 174/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1571 - accuracy: 0.9561\n",
            "Epoch 174: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 792ms/step - loss: 0.1571 - accuracy: 0.9561 - val_loss: 0.8804 - val_accuracy: 0.7865\n",
            "Epoch 175/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1367 - accuracy: 0.9561\n",
            "Epoch 175: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 681ms/step - loss: 0.1367 - accuracy: 0.9561 - val_loss: 0.8834 - val_accuracy: 0.7528\n",
            "Epoch 176/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0843 - accuracy: 0.9737\n",
            "Epoch 176: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 9s 799ms/step - loss: 0.0843 - accuracy: 0.9737 - val_loss: 0.9216 - val_accuracy: 0.7753\n",
            "Epoch 177/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1469 - accuracy: 0.9474\n",
            "Epoch 177: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 10s 889ms/step - loss: 0.1469 - accuracy: 0.9474 - val_loss: 0.9388 - val_accuracy: 0.7640\n",
            "Epoch 178/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1026 - accuracy: 0.9678\n",
            "Epoch 178: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 7s 666ms/step - loss: 0.1026 - accuracy: 0.9678 - val_loss: 0.9167 - val_accuracy: 0.7753\n",
            "Epoch 179/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1375 - accuracy: 0.9591\n",
            "Epoch 179: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 775ms/step - loss: 0.1375 - accuracy: 0.9591 - val_loss: 0.8822 - val_accuracy: 0.7865\n",
            "Epoch 180/180\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1549 - accuracy: 0.9561\n",
            "Epoch 180: val_accuracy did not improve from 0.83146\n",
            "11/11 [==============================] - 8s 769ms/step - loss: 0.1549 - accuracy: 0.9561 - val_loss: 0.9329 - val_accuracy: 0.7978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot accuracy imporvement over training epochs"
      ],
      "metadata": {
        "id": "rrHZPT6CdsFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, \"b\", label=\"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, \"r\", label=\"Validation Accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.legend(loc=0)\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epochs, loss, \"b\", label=\"Training Loss\")\n",
        "plt.plot(epochs, val_loss, \"r\", label=\"Validation Loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.legend(loc=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "id": "0ZqePnGbr9mO",
        "outputId": "ecd2ba4c-0285-44a9-93cf-28e7570dc69d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate model"
      ],
      "metadata": {
        "id": "lN5OX2dDdygJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results = model.evaluate(\n",
        "  val_generator,\n",
        "  batch_size=32,\n",
        "  verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhUpAKxIyktU",
        "outputId": "66b30ef1-f5e1-4594-e747-62dbaf21e6c4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 20s 4s/step - loss: 0.7133 - accuracy: 0.8315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save model checkpoints, .h5 file, and .tflite file"
      ],
      "metadata": {
        "id": "h8T1vZhsd0Ln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/incv3ckpt70.h5\")\n"
      ],
      "metadata": {
        "id": "koGUvIM1_rbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(model, \"/content/drive/MyDrive/savedmodel\")\n",
        "\n",
        "tflite_converter = tf.lite.TFLiteConverter.from_saved_model(\"/content/drive/MyDrive/savedmodel\")\n",
        "tflite_model = tflite_converter.convert()\n",
        "\n",
        "tflite_model_file = pathlib.Path(\"/content/drive/MyDrive/incv3ckpt70.tflite\")\n",
        "tflite_model_file.write_bytes(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0i3Ad2fYeDI",
        "outputId": "6c7659f5-1e68-4ce0-d3e0-48e8e887b0db"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 95). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "299476688"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/inceptionbb-checkpoints-2/70.ckpt.data-00000-of-00001 /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "9_GG62X3tYks"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}